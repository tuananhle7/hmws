{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c18b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Notebook to debug figure plots, e.g. sampling from memory\n",
    "'''\n",
    "\n",
    "import os\n",
    "\n",
    "import cmws\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from cmws import util\n",
    "from cmws.examples.scene_understanding import data, render, run\n",
    "from cmws.examples.scene_understanding import util as scene3d_util \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from cmws.examples.scene_understanding.plot import *\n",
    "\n",
    "\n",
    "def importance_sample_memory(\n",
    "    num_particles, obs, obs_id, generative_model, guide, memory, img_size=256\n",
    "):\n",
    "    # modifed from: https://github.com/tuananhle7/continuous_mws/blob/a43dd325e1e2c765d9811773ff5885b6f5f400e4/cmws/examples/timeseries/inference.py#L239\n",
    "    \"\"\"\n",
    "    Args\n",
    "        num_particles\n",
    "        num_svi_iterations\n",
    "        obs [batch_size, num_timesteps]\n",
    "        obs_id [batch_size]\n",
    "        generative_model\n",
    "        guide\n",
    "        memory\n",
    "    Returns\n",
    "        latent\n",
    "            raw_expression [memory_size, batch_size, max_num_chars]\n",
    "            eos [memory_size, batch_size, max_num_chars]\n",
    "            raw_gp_params [memory_size, batch_size, max_num_chars, gp_params_dim]\n",
    "        log_marginal_joint [memory_size, batch_size]\n",
    "    \"\"\"\n",
    "    # Extract\n",
    "    batch_size = obs.shape[0]\n",
    "    memory_size = memory.size\n",
    "    \n",
    "    print(\"sampling discrete\")\n",
    "\n",
    "    # Sample discrete latent\n",
    "    # [memory_size, batch_size, ...]\n",
    "    discrete_latent = memory.select(obs_id)\n",
    "    \n",
    "    print(\"computing scores\")\n",
    "\n",
    "    # COMPUTE SCORES s_i = log p(d_i, x) for i  {1, ..., M}\n",
    "    # [memory_size, batch_size]\n",
    "    log_marginal_joint = cmws.losses.get_log_marginal_joint(\n",
    "        generative_model, guide, discrete_latent, obs, num_particles\n",
    "    )\n",
    "    \n",
    "    print(\"expanding and getting continuous\")\n",
    "\n",
    "    # Sample svi-optimized q(z_c | z_d, x)\n",
    "    # -- Expand obs\n",
    "    # [memory_size, batch_size, 3, img_size, img_size]\n",
    "    obs_expanded = obs[None].expand([memory_size, batch_size, 3, img_size, img_size])\n",
    "    # -- SVI\n",
    "    continuous_latent = guide.sample_continuous(obs_expanded, discrete_latent)\n",
    "\n",
    "    # Combine latents\n",
    "    latent = discrete_latent[0], discrete_latent[1], continuous_latent\n",
    "\n",
    "    return latent, log_marginal_joint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0850ae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color status:  False\n",
      "path:  /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data/1_1/cube_0.01/train.pt\n",
      "19:20:56 | /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data.py:348 | INFO: Loading dataset (test = False)...\n",
      "19:20:56 | /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data.py:352 | INFO: Dataset (test = False) loaded /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data/1_1/cube_0.01/train.pt\n",
      "19:20:56 | /om/user/katiemc/continuous_mws/cmws/memory.py:20 | INFO: Initializing memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 571.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:20:57 | /om/user/katiemc/continuous_mws/cmws/util.py:293 | INFO: Saved to save/cmws_vs_rws_learnColor/cmws_5_2_0.01_2/stats.png\n",
      "color status:  False\n",
      "path:  /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data/2_2/cube_0.01/train.pt\n",
      "19:20:57 | /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data.py:348 | INFO: Loading dataset (test = False)...\n",
      "19:20:58 | /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data.py:352 | INFO: Dataset (test = False) loaded /om/user/katiemc/continuous_mws/cmws/examples/scene_understanding/data/2_2/cube_0.01/train.pt\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"cmws_vs_rws_learnColor\"\n",
    "device = \"cpu\"\n",
    "save_dir = f\"../save/{experiment_name}\"\n",
    "checkpoint_paths = []\n",
    "for config_name in sorted(os.listdir(save_dir)):\n",
    "    checkpoint_paths.append(util.get_checkpoint_path(experiment_name, config_name, -1))\n",
    "checkpoint_path = 'save/cmws_vs_rws_learnColor/cmws_5_2_0.01_2/checkpoints/latest.pt'#checkpoint_paths[0]\n",
    "checkpoint_path = f\"../{checkpoint_path}\"\n",
    "model, optimizer, stats, run_args = scene3d_util.load_checkpoint(\n",
    "                            checkpoint_path, device=\"cpu\"\n",
    "                        )\n",
    "generative_model, guide = model[\"generative_model\"], model[\"guide\"]\n",
    "num_iterations = len(stats.losses) # note: can use to filter out jobs!\n",
    "save_dir = util.get_save_dir(run_args.experiment_name, run.get_config_name(run_args))\n",
    "\n",
    "# Plot stats\n",
    "plot_stats(f\"{save_dir}/stats.png\", stats)\n",
    "\n",
    "# Plot reconstructions and other things\n",
    "# Test data\n",
    "# NOTE: Plotting the train dataset only\n",
    "train_dataset = data.SceneUnderstandingDataset(\n",
    "    device, run_args.num_grid_rows, run_args.num_grid_cols, test=False,\n",
    "    remove_color=(run_args.remove_color == 1),\n",
    "    mode=run_args.mode\n",
    ")\n",
    "obs, obs_id = train_dataset[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8f7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = model[\"memory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df81288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling discrete\n",
      "computing scores\n",
      "raw locations OBS:  torch.Size([5, 5, 10, 2, 2, 3])\n",
      "SIZES:  torch.Size([250, 4, 3])\n",
      "expanding and getting continuous\n"
     ]
    }
   ],
   "source": [
    "obs = obs.squeeze(1)\n",
    "num_test_obs, num_channels, im_size, _ = obs.shape\n",
    "im_size = 128\n",
    "num_samples = 1\n",
    "\n",
    "num_particles = memory.size\n",
    "latent, log_weight = importance_sample_memory(\n",
    "    num_particles, obs, obs_id, generative_model, guide, memory, im_size\n",
    ")\n",
    "\n",
    "num_blocks, stacking_program, raw_locations = latent\n",
    "\n",
    "# Sort by log weight\n",
    "# [num_test_obs, num_particles], [num_test_obs, num_particles]\n",
    "_, sorted_indices = torch.sort(log_weight.T, descending=True)\n",
    "\n",
    "# Sample predictions\n",
    "# -- Expand obs\n",
    "obs_expanded = obs[None].expand(num_particles, num_test_obs, 3, im_size, im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593e80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -- Sample predictions\n",
    "# obs_predictions = generative_model.sample_obs_predictions(latent, obs_expanded, [num_samples])\n",
    "# predictive_dist = generative_model.get_predictive_dist(latent, obs_expanded)\n",
    "# predictive_mean = predictive_dist.loc\n",
    "# predictive_std = predictive_dist.covariance_matrix.diagonal(dim1=-2, dim2=-1).sqrt()\n",
    "# predictive_low = predictive_mean - 2 * predictive_std\n",
    "# predictive_high = predictive_mean + 2 * predictive_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f67d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b2108037450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_obs_id = 3\n",
    "particle_id = 0 \n",
    "\n",
    "sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellow_multiplier = [0.5, 0.5, 0]\n",
    "# plt.imshow(img * yellow_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e954e4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b210807ce10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "sampled_obs = generative_model.get_obs_loc(sampled_latent)\n",
    "\n",
    "img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72dd6577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 3, 128, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_expanded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e492773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-45290.4219, -45289.4766, -45250.1719, -45248.9648, -45201.6836],\n",
       "        [-45258.4609, -45256.6484, -45253.2070, -45235.2969, -45219.8320],\n",
       "        [-45276.3750, -45268.0859, -45262.3242, -45243.8633, -45208.4766],\n",
       "        [-45270.7734, -45271.1562, -45264.5469, -45262.3320, -45217.9688],\n",
       "        [-45285.4180, -45279.0469, -45258.2578, -45250.9023, -45218.2031],\n",
       "        [-45271.5312, -45264.7109, -45269.1328, -45248.3086, -45240.0273],\n",
       "        [-45269.3125, -45278.6055, -45262.5938, -45267.2852, -45221.5781],\n",
       "        [-45265.3125, -45260.0234, -45260.1289, -45244.5195, -45240.6719],\n",
       "        [-45251.7305, -45241.8125, -45245.2812, -45236.7539, -45213.8242],\n",
       "        [-45238.7305, -45237.6758, -45227.3750, -45207.3867, -45207.4180]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49e99b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_weight.T[0][0].item() < log_weight.T[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b611b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.gridspec as gridspec\n",
    "# text_width = 6.75\n",
    "# column_width = 6.5 / 2.\n",
    "# text_height = 9.\n",
    "# golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "# rows = 4\n",
    "# cols = 3#5\n",
    "\n",
    "# # for the samples from memory\n",
    "# views = [-40, 40] # azimuths\n",
    "# num_views = len(views)\n",
    "# num_samples = 3 \n",
    "\n",
    "# num_primitives = generative_model.num_primitives\n",
    "\n",
    "# # gridspec inside gridspec\n",
    "# f = plt.figure(figsize=(8,6), dpi=600)\n",
    "# # f = plt.figure(figsize=(text_width, rows/cols * text_width), dpi=600)\n",
    "# gs0 = gridspec.GridSpec(rows, cols, figure=f)\n",
    "\n",
    "# high_res_img = 256\n",
    "\n",
    "# generative_model.im_size = high_res_img#512 # change for higher res\n",
    "\n",
    "# for x in range(rows):\n",
    "#     if x >= 2: \n",
    "#         if x == 3: # show primitives\n",
    "#             # 1 row, num primitives = num cols\n",
    "#             print(\"in grid spec\")\n",
    "#             gs00 = gridspec.GridSpecFromSubplotSpec(1, num_primitives, subplot_spec=gs0[x, 0:],\n",
    "#                                                wspace=0.025, hspace=0)\n",
    "#             # Init\n",
    "#             location = torch.tensor([0, 0, -1], device=device).float()\n",
    "#             for i in range(num_primitives): \n",
    "#                 print(\"primitive: \", i)\n",
    "#                 ax = f.add_subplot(gs00[0, i])\n",
    "#                 obs = render.render_block(\n",
    "#                     generative_model.primitives[i].size,\n",
    "#                     generative_model.primitives[i].color,\n",
    "#                     location,\n",
    "#                     im_size=high_res_img,\n",
    "#                     remove_color=False,\n",
    "#                     mode=\"cube\",\n",
    "# #                     camera_elevation=30,\n",
    "# #                     camera_azimuth=40\n",
    "#                 )\n",
    "#                 ax.imshow(obs.detach().numpy())\n",
    "#                 print(\"created image: \", obs.shape)\n",
    "#                 ax.set_xticks([])\n",
    "#                 ax.set_yticks([])\n",
    "#                 if i == 0: # middle entry\n",
    "#                     ax.set_ylabel(f'Primitives', fontsize=10, fontfamily='serif')\n",
    "#             continue # skip the inner loop of cols \n",
    "#         else: continue \n",
    "#     for y in range(cols):\n",
    "#         test_obs_id = y \n",
    "#         if x == 0: # observations \n",
    "#             ax = f.add_subplot(gs0[x, y])\n",
    "#             img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "#             ax.imshow(img)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             if y == 0: # middle entry\n",
    "#                 ax.set_ylabel(f'Observations', fontsize=10)#, fontfamily='serif')\n",
    "#         else: \n",
    "#             gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x:-1, y],\n",
    "#                                                wspace=-0.5, hspace=0.0)#wspace=0.025, hspace=0.0)\n",
    "#             for xx in range(num_samples): \n",
    "#                 for yy in range(num_views): \n",
    "#                     print(\"yy: \", yy)\n",
    "#                     ax = f.add_subplot(gs00[xx, yy])\n",
    "                    \n",
    "#                     particle_id = xx\n",
    "#                     sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "#                     num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "#                     stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "#                     raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "#                     sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "#                     camera_elevation = 30\n",
    "#                     camera_azimuth = views[yy]\n",
    "\n",
    "#                     sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "#                     img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "#                     ax.imshow(img)\n",
    "#                     ax.set_xticks([])\n",
    "#                     ax.set_yticks([])\n",
    "#                     if y == 0 and yy == 0 and xx == 1: # middle entry\n",
    "#                         print(\"adding title!\")\n",
    "#                         ax.set_ylabel(f'Posterior Samples', fontsize=10, fontfamily='serif')\n",
    "\n",
    "# path = \"learnColor_samples.pdf\"\n",
    "# util.save_fig(f, path, dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c42ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.gridspec as gridspec\n",
    "# text_width = 6.75\n",
    "# column_width = 6.5 / 2.\n",
    "# text_height = 9.\n",
    "# golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "# rows = 7\n",
    "# cols = 3#5\n",
    "\n",
    "# # for the samples from memory\n",
    "# views = [-40, 40] # azimuths\n",
    "# num_views = len(views)\n",
    "# num_samples = 3 \n",
    "\n",
    "# example_idxs = [0, 1,2]\n",
    "\n",
    "# num_primitives = generative_model.num_primitives\n",
    "\n",
    "# # gridspec inside gridspec\n",
    "# f = plt.figure(figsize=(6,6), dpi=600)\n",
    "# # f = plt.figure(figsize=(text_width, rows/cols * text_width), dpi=600)\n",
    "# gs0 = gridspec.GridSpec(rows, cols, figure=f)\n",
    "\n",
    "# high_res_img = 256\n",
    "\n",
    "# axis_size = 14\n",
    "# title_size = 20 \n",
    "\n",
    "# generative_model.im_size = high_res_img#512 # change for higher res\n",
    "\n",
    "# for x in range(rows):\n",
    "#     if x == 1: continue \n",
    "#     if x >= 3: \n",
    "#         if x == rows-1: # show primitives\n",
    "#             # 1 row, num primitives = num cols\n",
    "#             gs00 = gridspec.GridSpecFromSubplotSpec(1, num_primitives, subplot_spec=gs0[x, 0:],\n",
    "#                                                wspace=0.025, hspace=0)\n",
    "#             # Init\n",
    "#             location = torch.tensor([0, 0, -1], device=device).float()\n",
    "#             for i in range(num_primitives): \n",
    "#                 ax = f.add_subplot(gs00[0, i])\n",
    "#                 obs = render.render_block(\n",
    "#                     generative_model.primitives[i].size,\n",
    "#                     generative_model.primitives[i].color,\n",
    "#                     location,\n",
    "#                     im_size=high_res_img,\n",
    "#                     remove_color=run_args.remove_color==1,\n",
    "#                     mode=\"cube\",\n",
    "#                 )\n",
    "#                 ax.imshow(obs.detach().numpy())\n",
    "#                 ax.set_xticks([])\n",
    "#                 ax.set_yticks([])\n",
    "#                 if i == 0: # middle entry\n",
    "#                     ax.set_ylabel(f'Primitives', fontsize=11)\n",
    "#             continue # skip the inner loop of cols \n",
    "#         else: continue \n",
    "#     for y in range(cols):\n",
    "#         test_obs_id = example_idxs[y] \n",
    "#         if x == 0: # observations \n",
    "#             ax = f.add_subplot(gs0[:2, y])\n",
    "#             img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "#             ax.imshow(img)\n",
    "#             ax.set_xticks([])\n",
    "#             ax.set_yticks([])\n",
    "#             if y == 0: # middle entry\n",
    "#                 ax.set_ylabel(f'Observations', fontsize=axis_size)#, fontfamily='serif')\n",
    "#             if y == 1: # middle\n",
    "#                 ax.set_title(\"Learning Shape and Color\", fontsize=title_size,pad=10)\n",
    "#         else: \n",
    "#             gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x:-1, y],\n",
    "#                                                wspace=0.0, hspace=0.0)#wspace=0.025, hspace=0.0)\n",
    "#             for xx in range(num_samples): \n",
    "#                 for yy in range(num_views): \n",
    "#                     ax = f.add_subplot(gs00[xx, yy])\n",
    "                    \n",
    "#                     particle_id = xx\n",
    "#                     sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "#                     num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "#                     stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "#                     raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "#                     sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "#                     camera_elevation = 30\n",
    "#                     camera_azimuth = views[yy]\n",
    "\n",
    "#                     sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "#                     img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "#                     ax.imshow(img)\n",
    "#                     ax.set_xticks([])\n",
    "#                     ax.set_yticks([])\n",
    "#                     if y == 0 and yy == 0 and xx == 1: # middle entry\n",
    "#                         ax.set_ylabel(f'Posterior Samples', fontsize=axis_size)\n",
    "\n",
    "# path = \"learnColor_samples.pdf\"\n",
    "# util.save_fig(f, path, dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b31d0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "SIZES:  torch.Size([1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om/user/katiemc/continuous_mws/cmws/util.py:291: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout(**tight_layout_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:30:30 | /om/user/katiemc/continuous_mws/cmws/util.py:293 | INFO: Saved to learnColor_samples.pdf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "text_width = 6.75\n",
    "column_width = 6.5 / 2.\n",
    "text_height = 9.\n",
    "golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "rows = 7\n",
    "cols = 3#5\n",
    "\n",
    "# for the samples from memory\n",
    "views = [-40, 40] # azimuths\n",
    "num_views = len(views)\n",
    "num_samples = 3 \n",
    "\n",
    "example_idxs = [0, 1,2]\n",
    "\n",
    "num_primitives = generative_model.num_primitives\n",
    "\n",
    "# gridspec inside gridspec\n",
    "f = plt.figure(figsize=(6,6), dpi=600)\n",
    "# f = plt.figure(figsize=(text_width, rows/cols * text_width), dpi=600)\n",
    "gs0 = gridspec.GridSpec(rows, cols, figure=f)\n",
    "\n",
    "high_res_img = 512\n",
    "\n",
    "axis_size = 14\n",
    "title_size = 20 \n",
    "\n",
    "generative_model.im_size = high_res_img#512 # change for higher res\n",
    "\n",
    "for x in range(rows):\n",
    "    if x == 1: continue \n",
    "    if x >= 3: \n",
    "        if x == rows-1: # show primitives\n",
    "            # 1 row, num primitives = num cols\n",
    "            gs00 = gridspec.GridSpecFromSubplotSpec(1, num_primitives, subplot_spec=gs0[x, 0:],\n",
    "                                               wspace=0.025, hspace=0)\n",
    "            # Init\n",
    "            location = torch.tensor([0, 0, -1], device=device).float()\n",
    "            for i in range(num_primitives): \n",
    "                ax = f.add_subplot(gs00[0, i])\n",
    "                obs = render.render_block(\n",
    "                    generative_model.primitives[i].size,\n",
    "                    generative_model.primitives[i].color,\n",
    "                    location,\n",
    "                    im_size=high_res_img,\n",
    "                    remove_color=run_args.remove_color==1,\n",
    "                    mode=\"cube\",\n",
    "                )\n",
    "                ax.imshow(obs.detach().numpy())\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                if i == 0: # middle entry\n",
    "                    ax.set_ylabel(f'Primitives', fontsize=11)\n",
    "                    axins = inset_axes(ax, width=\"40%\", height=\"30%\")#,loc=3)\n",
    "                    #axins = inset_axes(ax, width=0.2, height=0.15)#width=0.7, height=0.5)#(ax, width=1.3, height=0.9)\n",
    "                    minimap = plt.imread(\"../front_camera.png\")\n",
    "                    axins.imshow(minimap)\n",
    "                    axins.set_xticks([])\n",
    "                    axins.set_yticks([])\n",
    "                    axins.axis('off')\n",
    "            continue # skip the inner loop of cols \n",
    "        else: continue \n",
    "    for y in range(cols):\n",
    "        test_obs_id = example_idxs[y] \n",
    "        if x == 0: # observations \n",
    "            ax = f.add_subplot(gs0[:2, y])\n",
    "            img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "            ax.imshow(img)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            if y == 0: # middle entry\n",
    "                ax.set_ylabel(f'Observations', fontsize=axis_size)#, fontfamily='serif')\n",
    "                axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "#                 axins = inset_axes(ax, width=0.4, height=0.3)#(ax, width=1.3, height=0.9)\n",
    "                minimap = plt.imread(\"../front_camera.png\")\n",
    "                axins.imshow(minimap)\n",
    "                axins.set_xticks([])\n",
    "                axins.set_yticks([])\n",
    "                axins.axis('off')\n",
    "            if y == 1: # middle\n",
    "                ax.set_title(\"Inferring shape with color\", fontsize=title_size,pad=10)\n",
    "        else: \n",
    "            gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x:-1, y],\n",
    "                                               wspace=0.0, hspace=0.0)#wspace=0.025, hspace=0.0)\n",
    "            for xx in range(num_samples): \n",
    "                for yy in range(num_views): \n",
    "                    ax = f.add_subplot(gs00[xx, yy])\n",
    "                    \n",
    "                    particle_id = xx\n",
    "                    sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "                    num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "                    stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "                    raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "                    sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "                    camera_elevation = 30\n",
    "                    camera_azimuth = views[yy]\n",
    "\n",
    "                    sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "                    img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "                    ax.imshow(img)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    if y == 0:\n",
    "                        if yy == 0:\n",
    "                            if xx == 0: \n",
    "                                axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "                                minimap = plt.imread(\"../left_camera.png\")\n",
    "                                axins.imshow(minimap)\n",
    "                                axins.set_xticks([])\n",
    "                                axins.set_yticks([])\n",
    "                                axins.axis('off')\n",
    "                            if xx == 1: # middle entry\n",
    "                                ax.set_ylabel(f'Posterior Samples', fontsize=axis_size)\n",
    "                        if yy == 1 and xx == 0:\n",
    "                            axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "                            minimap = plt.imread(\"../right_camera.png\")\n",
    "                            axins.imshow(minimap)\n",
    "                            axins.set_xticks([])\n",
    "                            axins.set_yticks([])\n",
    "                            axins.axis('off')\n",
    "\n",
    "path = \"learnColor_samples.pdf\"\n",
    "util.save_fig(f, path, dpi=400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452fa64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260c6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_grid(num_rows, num_cols, filename_list, trgt_name, fig_size, col_headers=None,\n",
    "             wspace=0.05, hspace=0.05, dpi=600, trgt_root_dir='./sample_plots/',\n",
    "             col_headersize=4):\n",
    "    '''Plot images on a grid with optional column headers.'''\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=fig_size, dpi=dpi)\n",
    "    for i, (ax, filename) in enumerate(zip(axes.flat, filename_list)):\n",
    "        if i < num_cols and col_headers:\n",
    "            ax.set_title(col_headers[i], fontsize=col_headersize, fontfamily='serif', pad=2.)\n",
    "\n",
    "        if filename is not None:\n",
    "            img = imageio.imread(filename)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.close(fig)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "\n",
    "    util.cond_mkdir(os.path.dirname(trgt_root_dir))\n",
    "\n",
    "    trgt_path = os.path.join(trgt_root_dir, trgt_name)\n",
    "    print(f\"Saving figure {trgt_path}\")\n",
    "    fig.savefig(trgt_path, bbox='tight', bbox_inches='tight', pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71d715dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katiemc/.conda/envs/cmws/lib/python3.7/site-packages/ipykernel_launcher.py:111: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "/om/user/katiemc/continuous_mws/cmws/util.py:291: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout(**tight_layout_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:32:32 | /om/user/katiemc/continuous_mws/cmws/util.py:293 | INFO: Saved to learnColor_samples.pdf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "col_headersize = 11\n",
    "# inches\n",
    "text_width = 6.75\n",
    "column_width = 6.5 / 2.\n",
    "text_height = 9.\n",
    "golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "axis_size = 14\n",
    "title_size = 20\n",
    "\n",
    "# select cars + imgs for context views\n",
    "# all_items = os.listdir(model_sample_dirs[0][0])\n",
    "# car_id = np.random.choice(all_items, 1)[0]\n",
    "\n",
    "# for the samples from memory\n",
    "views = [0, -40, 40] # azimuths\n",
    "num_views = len(views)\n",
    "num_samples = 3 \n",
    "\n",
    "example_idxs = [0, 1,2]\n",
    "\n",
    "num_primitives = generative_model.num_primitives\n",
    "\n",
    "high_res_img = 256\n",
    "generative_model.im_size = high_res_img\n",
    "\n",
    "# Get the 3 context views\n",
    "#ctxt_imgs = [os.path.join(specific_views_dir, car_id, \"rgb\", convert_view2file(idx)) for idx in range(3)]\n",
    "\n",
    "# Get 3 samples for single, double, and triple views\n",
    "#view_ids = 0, 1, 2\n",
    "\n",
    "rows = len(example_idxs) # number of examples \n",
    "cols = 2 # observation + hmws \n",
    "\n",
    "# gridspec inside gridspec\n",
    "f = plt.figure(figsize=(text_width, rows/cols * text_width), dpi=600)\n",
    "gs0 = gridspec.GridSpec(rows, cols, figure=f)\n",
    "\n",
    "for x in range(rows):\n",
    "    \n",
    "    test_obs_id = example_idxs[x]\n",
    "    \n",
    "    # Context images\n",
    "    ax = f.add_subplot(gs0[x, 0])\n",
    "    if not x: ax.set_title(\"Observations\", fontsize=axis_size, pad=2.)\n",
    "    img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "    ax.imshow(img)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if x == 0: \n",
    "        #ax.set_ylabel(f'Observations', fontsize=axis_size)#, fontfamily='serif')\n",
    "        axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "#                 axins = inset_axes(ax, width=0.4, height=0.3)#(ax, width=1.3, height=0.9)\n",
    "        minimap = plt.imread(\"../front_camera.png\")\n",
    "        axins.imshow(minimap)\n",
    "        axins.set_xticks([])\n",
    "        axins.set_yticks([])\n",
    "        axins.axis('off')\n",
    "    \n",
    "    for y in range(cols - 1):\n",
    "        gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x, y + 1], \n",
    "                                                wspace=-0.01, hspace=-0.3)#wspace=0.05, hspace=-0.3)\n",
    "        # One row per sample\n",
    "        for xx in range(3):\n",
    "            # One column per view\n",
    "            for yy in range(3):\n",
    "                ax = f.add_subplot(gs00[xx, yy])\n",
    "                particle_id = xx\n",
    "                sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "                num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "                stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "                raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "                sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "                \n",
    "                camera_azimuth = views[yy]\n",
    "                if camera_azimuth == 0: camera_elevation = 0.1 # default\n",
    "                else: camera_elevation = 30\n",
    "\n",
    "                sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "                img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "                ax.imshow(img)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "                if not x and not xx and yy == 1: # First outer row, first inner row, center plot\n",
    "                    ax.set_title(\"Posterior Samples\", fontsize=axis_size, pad=10.)\n",
    "\n",
    "                if not yy and not y: # Leftmost view of samples\n",
    "                    ax.set_ylabel(f'Sample {xx+1}', fontsize=10)\n",
    "                \n",
    "                if x == 0 and xx == 0: \n",
    "                    axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "                    if yy == 0: minimap = plt.imread(\"../front_camera.png\")\n",
    "                    elif yy == 1: minimap = plt.imread(\"../left_camera.png\")\n",
    "                    elif yy == 2: minimap = plt.imread(\"../right_camera.png\")\n",
    "                    axins.imshow(minimap)\n",
    "                    axins.set_xticks([])\n",
    "                    axins.set_yticks([])\n",
    "                    axins.axis('off')\n",
    "\n",
    "# \n",
    "f.tight_layout()\n",
    "f.suptitle(\"Inferring the scene parse with color\", fontsize=20)#, pad=10)\n",
    "path = \"learnColor_samples.pdf\"\n",
    "util.save_fig(f, path, dpi=400)\n",
    "plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff76ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katiemc/.conda/envs/cmws/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "/om/user/katiemc/continuous_mws/cmws/util.py:291: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout(**tight_layout_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:40:25 | /om/user/katiemc/continuous_mws/cmws/util.py:293 | INFO: Saved to learnColor_samples.pdf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "\n",
    "col_headersize = 11\n",
    "# inches\n",
    "text_width = 6.75\n",
    "column_width = 6.5 / 2.\n",
    "text_height = 9.\n",
    "golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "axis_size = 14\n",
    "title_size = 20\n",
    "\n",
    "# select cars + imgs for context views\n",
    "# all_items = os.listdir(model_sample_dirs[0][0])\n",
    "# car_id = np.random.choice(all_items, 1)[0]\n",
    "\n",
    "# for the samples from memory\n",
    "views = [0, -40, 40] # azimuths\n",
    "num_views = len(views)\n",
    "num_samples = 3 \n",
    "\n",
    "example_idxs = [0, 1,2]\n",
    "\n",
    "num_primitives = generative_model.num_primitives\n",
    "\n",
    "high_res_img = 256\n",
    "generative_model.im_size = high_res_img\n",
    "\n",
    "# Get the 3 context views\n",
    "#ctxt_imgs = [os.path.join(specific_views_dir, car_id, \"rgb\", convert_view2file(idx)) for idx in range(3)]\n",
    "\n",
    "# Get 3 samples for single, double, and triple views\n",
    "#view_ids = 0, 1, 2\n",
    "\n",
    "rows = len(example_idxs) # number of examples \n",
    "cols = 3 # observation + hmws \n",
    "\n",
    "# gridspec inside gridspec\n",
    "f = plt.figure(figsize=(text_width, (3/2) * text_width), dpi=600)\n",
    "gs0 = gridspec.GridSpec(rows, cols, figure=f)\n",
    "\n",
    "for x in range(rows):\n",
    "    \n",
    "    test_obs_id = example_idxs[x]\n",
    "    \n",
    "    # Context images\n",
    "    ax = f.add_subplot(gs0[x, 0])\n",
    "    if not x: ax.set_title(\"Observations\", fontsize=axis_size, pad=10.)\n",
    "    img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "    ax.imshow(img)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if x == 0: \n",
    "        #ax.set_ylabel(f'Observations', fontsize=axis_size)#, fontfamily='serif')\n",
    "        axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "#                 axins = inset_axes(ax, width=0.4, height=0.3)#(ax, width=1.3, height=0.9)\n",
    "        minimap = plt.imread(\"../front_camera.png\")\n",
    "        axins.imshow(minimap)\n",
    "        axins.set_xticks([])\n",
    "        axins.set_yticks([])\n",
    "        axins.axis('off')\n",
    "    \n",
    "    for y in range(cols - 1):\n",
    "        if y == 1: continue\n",
    "        gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x, y + 1:], \n",
    "                                                wspace=-0.57, hspace=0.0)#wspace=0.05, hspace=-0.3)\n",
    "        # One row per sample\n",
    "        for xx in range(3):\n",
    "            # One column per view\n",
    "            for yy in range(3):\n",
    "                ax = f.add_subplot(gs00[xx, yy])\n",
    "                particle_id = xx\n",
    "                sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "                num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "                stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "                raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "                sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "                \n",
    "                camera_azimuth = views[yy]\n",
    "                if camera_azimuth == 0: camera_elevation = 0.1 # default\n",
    "                else: camera_elevation = 30\n",
    "\n",
    "                sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "                img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "                ax.imshow(img)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "                if not x and not xx and yy == 1: # First outer row, first inner row, center plot\n",
    "                    ax.set_title(\"Posterior Samples\", fontsize=axis_size, pad=6.)\n",
    "\n",
    "                if not yy and not y: # Leftmost view of samples\n",
    "                    ax.set_ylabel(f'Sample {xx+1}', fontsize=10)\n",
    "                \n",
    "                if x == 0 and xx == 0: \n",
    "                    axins = inset_axes(ax, width=\"40%\", height=\"30%\")#(ax, width=1.3, height=0.9)\n",
    "                    if yy == 0: minimap = plt.imread(\"../front_camera.png\")\n",
    "                    elif yy == 1: minimap = plt.imread(\"../left_camera.png\")\n",
    "                    elif yy == 2: minimap = plt.imread(\"../right_camera.png\")\n",
    "                    axins.imshow(minimap)\n",
    "                    axins.set_xticks([])\n",
    "                    axins.set_yticks([])\n",
    "                    axins.axis('off')\n",
    "\n",
    "# \n",
    "f.tight_layout()\n",
    "f.suptitle(\"Inferring scene parse with color\", fontsize=20)#, pad=10)\n",
    "path = \"learnColor_samples.pdf\"\n",
    "util.save_fig(f, path, dpi=400)\n",
    "plt.close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc0e44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dedeac36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "adding title!\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "in grid spec\n",
      "primitive:  0\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  1\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  2\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  3\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  4\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  0\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "yy:  1\n",
      "raw locations OBS:  torch.Size([2, 2, 3])\n",
      "SIZES:  torch.Size([1, 4, 3])\n",
      "in grid spec\n",
      "primitive:  0\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  1\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  2\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  3\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "primitive:  4\n",
      "SIZES:  torch.Size([1, 1, 1])\n",
      "created image:  torch.Size([32, 32, 3])\n",
      "19:34:51 | /om/user/katiemc/continuous_mws/cmws/util.py:293 | INFO: Saved to sample_memory_domains.pdf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "text_width = 6.75\n",
    "column_width = 6.5 / 2.\n",
    "text_height = 9.\n",
    "golden = (1 + 5 ** 0.5) / 2 # golden ratio\n",
    "\n",
    "rows = 4\n",
    "cols = 3#5\n",
    "\n",
    "# for the samples from memory\n",
    "views = [-40, 40] # azimuths\n",
    "num_views = len(views)\n",
    "num_samples = 3 \n",
    "\n",
    "num_primitives = generative_model.num_primitives\n",
    "\n",
    "domains = [\"learnColor\", \"noColor\"]\n",
    "\n",
    "# gridspec inside gridspec\n",
    "f = plt.figure(figsize=(len(domains)*8,6), dpi=600)\n",
    "# f = plt.figure(figsize=(text_width, rows/cols * text_width), dpi=600)\n",
    "\n",
    "gs = gridspec.GridSpec(1, len(domains), figure=f)\n",
    "for idx, domain in enumerate(domains): \n",
    "    gs0 = gridspec.GridSpecFromSubplotSpec(rows, cols, subplot_spec=gs[0, idx],\n",
    "                                                   wspace=0.025, hspace=0)\n",
    "\n",
    "    high_res_img = 32\n",
    "\n",
    "    generative_model.im_size = high_res_img#512 # change for higher res\n",
    "\n",
    "    for x in range(rows):\n",
    "        if x >= 2: \n",
    "            if x == 3: # show primitives\n",
    "                # 1 row, num primitives = num cols\n",
    "                print(\"in grid spec\")\n",
    "                gs00 = gridspec.GridSpecFromSubplotSpec(1, num_primitives, subplot_spec=gs0[x, 0:],\n",
    "                                                   wspace=0.025, hspace=0)\n",
    "                # Init\n",
    "                location = torch.tensor([0, 0, -1], device=device).float()\n",
    "                for i in range(num_primitives): \n",
    "                    print(\"primitive: \", i)\n",
    "                    ax = f.add_subplot(gs00[0, i])\n",
    "                    obs = render.render_block(\n",
    "                        generative_model.primitives[i].size,\n",
    "                        generative_model.primitives[i].color,\n",
    "                        location,\n",
    "                        im_size=high_res_img,\n",
    "                        remove_color=(domain == \"noColor\"),\n",
    "                        mode=\"cube\",\n",
    "                    )\n",
    "                    ax.imshow(obs.detach().numpy())\n",
    "                    print(\"created image: \", obs.shape)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    if idx == 0 and i == 0: # leftmost column label only\n",
    "                        ax.set_ylabel(f'Primitives', fontsize=10, fontfamily='serif')\n",
    "                continue # skip the inner loop of cols \n",
    "            else: continue \n",
    "        for y in range(cols):\n",
    "            test_obs_id = y \n",
    "            if x == 0: # observations \n",
    "                ax = f.add_subplot(gs0[x, y])\n",
    "                img = obs_expanded[0][test_obs_id].permute(1,2,0)\n",
    "                ax.imshow(img)\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                if y == 0 and idx == 0: # middle entry\n",
    "                    ax.set_ylabel(f'Observations', fontsize=10, fontfamily='serif')\n",
    "            else: \n",
    "                gs00 = gridspec.GridSpecFromSubplotSpec(num_samples, num_views, subplot_spec=gs0[x:-1, y],\n",
    "                                                   wspace=-0.5, hspace=0)\n",
    "                for xx in range(num_samples): \n",
    "                    for yy in range(num_views): \n",
    "                        print(\"yy: \", yy)\n",
    "                        ax = f.add_subplot(gs00[xx, yy])\n",
    "\n",
    "                        particle_id = xx\n",
    "                        sorted_particle_id = sorted_indices[test_obs_id, particle_id]\n",
    "\n",
    "                        num_blocks_selected = num_blocks[sorted_particle_id, test_obs_id]\n",
    "                        stacking_program_selected = stacking_program[sorted_particle_id, test_obs_id]\n",
    "                        raw_locations_selected = raw_locations[sorted_particle_id, test_obs_id]\n",
    "\n",
    "                        sampled_latent = (num_blocks_selected, stacking_program_selected, raw_locations_selected)\n",
    "\n",
    "                        camera_elevation = 30\n",
    "                        camera_azimuth = views[yy]\n",
    "\n",
    "                        sampled_obs = generative_model.get_obs_loc(sampled_latent, (camera_elevation, camera_azimuth))\n",
    "\n",
    "                        img = sampled_obs.permute(1,2,0).detach().numpy()\n",
    "                        ax.imshow(img)\n",
    "                        ax.set_xticks([])\n",
    "                        ax.set_yticks([])\n",
    "                        if idx == 0 and y == 0 and yy == 0 and xx == 1: # middle entry (and ensure leftmost column)\n",
    "                            print(\"adding title!\")\n",
    "                            ax.set_ylabel(f'Posterior Samples', fontsize=10, fontfamily='serif')\n",
    "\n",
    "path = \"sample_memory_domains.pdf\"\n",
    "util.save_fig(f, path, dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44243474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
