{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model with true primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primitives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square:\n",
    "    def __init__(self, name, color, size):\n",
    "        self.name = name\n",
    "        self.color = color\n",
    "        self.size = size\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}(color={self.color.tolist()}, size={self.size.item():.1f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primitives = [\n",
    "#     Square(\"A\", torch.tensor([1.0, 0.0, 0.0], device=device), torch.tensor(0.1, device=device)),\n",
    "#     Square(\"B\", torch.tensor([0.0, 1.0, 0.0], device=device), torch.tensor(0.2, device=device)),\n",
    "#     Square(\"C\", torch.tensor([0.0, 0.0, 1.0], device=device), torch.tensor(0.3, device=device))\n",
    "# ]\n",
    "# num_primitives = len(primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the stacking program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_stacking_program(num_primitives, device):\n",
    "    # Init\n",
    "    stacking_program = []\n",
    "    num_sampled_primitives = 0\n",
    "\n",
    "    # Sample first primitive\n",
    "    primitive_id_logits = torch.ones((num_primitives,), device=device)\n",
    "    primitive_id = pyro.sample(f\"primitive_id_{num_sampled_primitives}\",\n",
    "                               pyro.distributions.Categorical(logits=primitive_id_logits))\n",
    "    num_sampled_primitives += 1\n",
    "    stacking_program.append([primitive_id])\n",
    "\n",
    "    # Sample the rest\n",
    "    end_program = False\n",
    "    while not end_program:\n",
    "        # Sample an action for the next primitive\n",
    "        # Action 0:     put to the left of existing stack\n",
    "        # Action 1:     put on existing stack 1\n",
    "        # ...\n",
    "        # Action N:     put on existing stack N\n",
    "        # Action N + 1: put to the right of existing stack\n",
    "        # Action N + 2: end program\n",
    "        num_actions = len(stacking_program) + 3\n",
    "        action_id_logits = torch.ones((num_actions,), device=device)\n",
    "        action_id = pyro.sample(f\"action_id_{num_sampled_primitives}\",\n",
    "                                pyro.distributions.Categorical(logits=action_id_logits))\n",
    "\n",
    "        if action_id == len(stacking_program) + 2:\n",
    "            # End program\n",
    "            end_program = True\n",
    "            break\n",
    "        else:\n",
    "            # Sample primitive\n",
    "            primitive_id_logits = torch.ones((num_primitives,), device=device)\n",
    "            primitive_id = pyro.sample(f\"primitive_id_{num_sampled_primitives}\",\n",
    "                                       pyro.distributions.Categorical(logits=primitive_id_logits))\n",
    "            num_sampled_primitives += 1\n",
    "\n",
    "            # Add to the stacking program based on previous action\n",
    "            if action_id == 0:\n",
    "                stacking_program.insert(0, [primitive_id])\n",
    "            elif action_id == len(stacking_program) + 1:\n",
    "                stacking_program.append([primitive_id])\n",
    "            else:\n",
    "                stacking_program[action_id - 1].append(primitive_id)\n",
    "\n",
    "    return stacking_program\n",
    "\n",
    "\n",
    "def stacking_program_to_str(stacking_program, primitives):\n",
    "    primitive_stacks = []\n",
    "    for stack in stacking_program:\n",
    "        primitive_stack = []\n",
    "        for primitive_id in stack:\n",
    "            primitive_stack.append(primitives[primitive_id].name)\n",
    "        primitive_stacks.append(primitive_stack)\n",
    "    return primitive_stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking_program = sample_stacking_program(num_primitives, device)\n",
    "# stacking_program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample continuous locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_raw_locations(stacking_program):\n",
    "    uniform_dist = pyro.distributions.Uniform(0, 1)\n",
    "    raw_locations = []\n",
    "    for stack_id, stack in enumerate(stacking_program):\n",
    "        primitive_raw_locations = []\n",
    "        for primitive_id, primitive in enumerate(stack):\n",
    "            primitive_raw_locations.append(pyro.sample(f\"stack_{stack_id}_primitive_{primitive_id}_raw_loc\",\n",
    "                                                       uniform_dist))\n",
    "        raw_locations.append(primitive_raw_locations)\n",
    "    return raw_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_locations = sample_raw_locations(stacking_program)\n",
    "# raw_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render stacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from raw locations to actual locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw_locations(raw_locations, stacking_program, primitives):\n",
    "    # Extract stack widths\n",
    "    stack_widths = []\n",
    "    for stack_id, stack in enumerate(stacking_program):\n",
    "        bottom_primitive_id = stack[0]\n",
    "        bottom_primitive = primitives[bottom_primitive_id]\n",
    "        stack_widths.append(bottom_primitive.size)\n",
    "\n",
    "    # Compute right limits\n",
    "    right_limits = [1.0]\n",
    "    for stack_width in reversed(stack_widths[1:]):\n",
    "        right_limits.insert(0, right_limits[0] - stack_width)\n",
    "\n",
    "    # Check whether limits are ok\n",
    "    if stack_widths[0] > right_limits[0]:\n",
    "        print(\"error\")\n",
    "    else:\n",
    "        print(\"ok\")\n",
    "\n",
    "    # Compute bottom locations\n",
    "    y = torch.tensor(-1., device=device)\n",
    "    current_x = -1.0\n",
    "    locations = []\n",
    "    for stack_id, (stack, primitive_raw_locations, right_limit) in enumerate(\n",
    "        zip(stacking_program, raw_locations, right_limits)\n",
    "    ):\n",
    "        # Bottom primitive\n",
    "        bottom_primitive_id = stack[0]\n",
    "        bottom_primitive = primitives[bottom_primitive_id]\n",
    "        bottom_primitive_raw_location = primitive_raw_locations[0]\n",
    "\n",
    "        min_x = current_x\n",
    "        max_x = right_limit - bottom_primitive.size\n",
    "        x = bottom_primitive_raw_location * (max_x - min_x) + min_x\n",
    "        current_x = x + bottom_primitive.size\n",
    "        locations.append([torch.stack([x, y])])\n",
    "\n",
    "\n",
    "    # Compute the locations of the rest of the primitives\n",
    "    for stack_id, (stack, primitive_raw_locations) in enumerate(zip(stacking_program, raw_locations)):\n",
    "        for primitive_order, primitive_id in enumerate(stack):\n",
    "            if primitive_order != 0:\n",
    "                size_bottom = primitives[stack[primitive_order - 1]].size\n",
    "                size = primitives[primitive_id].size\n",
    "                primitive_raw_location = primitive_raw_locations[primitive_order]\n",
    "                x_bottom, y_bottom = locations[stack_id][-1]\n",
    "                y = y_bottom + size_bottom\n",
    "                min_x = x_bottom\n",
    "                max_x = x_bottom + size_bottom / 2\n",
    "                x = primitive_raw_location * (max_x - min_x) + min_x\n",
    "                locations[stack_id].append(torch.stack([x, y]))\n",
    "\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations = convert_raw_locations(raw_locations, stacking_program, primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_canvas_xy(num_rows, num_cols, device):\n",
    "    \"\"\"Create xy points on the canvas\n",
    "\n",
    "    Args\n",
    "        num_rows (int)\n",
    "        num_cols (int)\n",
    "\n",
    "    Returns\n",
    "        canvas_x [num_rows, num_cols]\n",
    "        canvas_y [num_rows, num_cols]\n",
    "    \"\"\"\n",
    "\n",
    "    x_range = torch.linspace(-1, 1, steps=num_cols, device=device)\n",
    "    y_range = torch.linspace(-1, 1, steps=num_rows, device=device).flip(dims=[0])\n",
    "    # [num_cols, num_rows]\n",
    "    canvas_x, canvas_y = torch.meshgrid(x_range, y_range)\n",
    "    # [num_rows, num_cols]\n",
    "    canvas_x, canvas_y = canvas_x.T, canvas_y.T\n",
    "\n",
    "    return canvas_x, canvas_y\n",
    "\n",
    "\n",
    "def render_square(square, location, canvas):\n",
    "    \"\"\"Draws a square on a canvas whose xy limits are [-1, 1].\n",
    "\n",
    "    Args\n",
    "        square\n",
    "        location [2]\n",
    "        canvas [num_channels, num_rows, num_cols]\n",
    "\n",
    "    Returns\n",
    "        new_canvas [num_channels, num_rows, num_cols]\n",
    "    \"\"\"\n",
    "    # Extract\n",
    "    # []\n",
    "    min_x, min_y = location\n",
    "    max_x = min_x + square.size\n",
    "    max_y = min_y + square.size\n",
    "    num_rows, num_cols = canvas.shape[-2:]\n",
    "    device = location.device\n",
    "\n",
    "    # Canvas xy\n",
    "    # [num_rows, num_cols]\n",
    "    canvas_x, canvas_y = get_canvas_xy(num_rows, num_cols, device)\n",
    "\n",
    "    # Draw on canvas\n",
    "    new_canvas = canvas.clone()\n",
    "    for channel_id in range(num_channels):\n",
    "        new_canvas[\n",
    "            channel_id,\n",
    "            (canvas_x >= min_x) & (canvas_x <= max_x) & (canvas_y >= min_y) & (canvas_y <= max_y)\n",
    "        ] -= (1 - square.color[channel_id])\n",
    "    new_canvas = new_canvas.clamp(0, 1)\n",
    "\n",
    "    return new_canvas\n",
    "\n",
    "\n",
    "def init_canvas(device, num_channels=3, num_rows=256, num_cols=256):\n",
    "     return torch.ones((num_channels, num_rows, num_cols), device=device)\n",
    "\n",
    "\n",
    "def render(primitives, stacking_program, raw_locations, num_channels=3, num_rows=256, num_cols=256):\n",
    "    # Convert\n",
    "    locations = convert_raw_locations(raw_locations, stacking_program, primitives)\n",
    "\n",
    "    # Render\n",
    "    canvas = init_canvas(device, num_channels, num_rows, num_cols)\n",
    "    for stack_id, stack in enumerate(stacking_program):\n",
    "        for primitive_order, primitive_id in enumerate(stack):\n",
    "            primitive = primitives[primitive_id]\n",
    "            location = locations[stack_id][primitive_order]\n",
    "            canvas = render_square(primitive, location, canvas)\n",
    "\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_channels, num_rows, num_cols = 3, 256, 256\n",
    "# canvas = torch.ones((num_channels, num_rows, num_cols), device=device)\n",
    "\n",
    "# for stack_id, stack in enumerate(stacking_program):\n",
    "#     for primitive_order, primitive_id in enumerate(stack):\n",
    "#         primitive = primitives[primitive_id]\n",
    "#         location = locations[stack_id][primitive_order]\n",
    "#         canvas = render_square(primitive, location, canvas)\n",
    "\n",
    "# plt.imshow(canvas.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['C']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define params\n",
    "primitives = [\n",
    "    Square(\"A\", torch.tensor([1.0, 0.0, 0.0], device=device), torch.tensor(0.1, device=device)),\n",
    "    Square(\"B\", torch.tensor([0.0, 1.0, 0.0], device=device), torch.tensor(0.2, device=device)),\n",
    "    Square(\"C\", torch.tensor([0.0, 0.0, 1.0], device=device), torch.tensor(0.3, device=device))\n",
    "]\n",
    "num_primitives = len(primitives)\n",
    "num_channels, num_rows, num_cols = 3, 256, 256\n",
    "\n",
    "# Sample\n",
    "stacking_program = sample_stacking_program(num_primitives, device)\n",
    "raw_locations = sample_raw_locations(stacking_program)\n",
    "\n",
    "# Render\n",
    "img = render(primitives, stacking_program, raw_locations)\n",
    "\n",
    "# Plot\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "stacking_program_to_str(stacking_program, primitives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learneable square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnableSquare(nn.Module):\n",
    "    def __init__(self, name):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.raw_color = nn.Parameter(torch.randn((3,)))\n",
    "        self.raw_size = nn.Parameter(torch.randn(()))\n",
    "    \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.raw_size.device\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        min_size = 0.01\n",
    "        max_size = 1.0\n",
    "        return self.raw_size.sigmoid() * (max_size - min_size) + min_size\n",
    "    \n",
    "    @property\n",
    "    def color(self):\n",
    "        return self.raw_color.sigmoid()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}(color={self.color.tolist()}, size={self.size.item():.1f})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an actual square we want to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7f657b4b10>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_square = Square(\"A\", torch.tensor([0.9, 0.2, 0.3], device=device), torch.tensor(0.3, device=device))\n",
    "true_location = torch.tensor([0.5, 0.5], device=device)\n",
    "img = render_square(true_square, true_location, init_canvas(device))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft rasterizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def get_min_edge_distance(square, location, point):\n",
    "    \"\"\"Computes shortest distance from a point to the square edge.\n",
    "    Negative if it's inside the square.\n",
    "    Positive if it's outside the square.\n",
    "    \n",
    "    Args\n",
    "        square\n",
    "        location [2]\n",
    "        point [*shape, 2]\n",
    "    \n",
    "    Returns [*shape]\n",
    "    \"\"\"\n",
    "    # Extract\n",
    "    device = location.device\n",
    "    # []\n",
    "    min_x, min_y = location\n",
    "    max_x = min_x + square.size\n",
    "    max_y = min_y + square.size\n",
    "    shape = point.shape[:-1]\n",
    "    # [*shape]\n",
    "    x, y = point[..., 0], point[..., 1]\n",
    "    \n",
    "    # Determine which area the point is in\n",
    "    # [*shape]\n",
    "    # --High level areas\n",
    "    up = (y >= max_y)\n",
    "    middle = (y >= min_y) & (y < max_y)\n",
    "    bottom = (y < min_y)\n",
    "    left = (x < min_x)\n",
    "    center = (x >= min_x) & (x < max_x)\n",
    "    right = (x >= max_x)\n",
    "    \n",
    "    # --Use high level areas to define smaller sectors which we're going to work with\n",
    "    area_1 = left & up\n",
    "    area_2 = center & up\n",
    "    area_3 = right & up\n",
    "    area_4 = left & middle\n",
    "    area_5 = center & middle\n",
    "    area_6 = right & middle\n",
    "    area_7 = left & bottom\n",
    "    area_8 = center & bottom\n",
    "    area_9 = right & bottom\n",
    "\n",
    "    # Compute min distances\n",
    "    # --Init the results\n",
    "    # [*shape]\n",
    "    min_edge_distance = torch.zeros_like(x)\n",
    "\n",
    "    # --Compute distances for points in the corners (areas 1, 3, 7, 9)\n",
    "    min_edge_distance[area_1] = torch.sqrt((x - min_x)**2 + (y - max_y)**2)[area_1]\n",
    "    min_edge_distance[area_3] = torch.sqrt((x - max_x)**2 + (y - max_y)**2)[area_3]\n",
    "    min_edge_distance[area_7] = torch.sqrt((x - min_x)**2 + (y - min_y)**2)[area_7]\n",
    "    min_edge_distance[area_9] = torch.sqrt((x - max_x)**2 + (y - min_y)**2)[area_9]\n",
    "\n",
    "    # --Compute distances for points in the outside strips (areas 2, 4, 6, 8)\n",
    "    min_edge_distance[area_2] = (y - max_y)[area_2]\n",
    "    min_edge_distance[area_4] = (min_x - x)[area_4]\n",
    "    min_edge_distance[area_6] = (x - max_x)[area_6]\n",
    "    min_edge_distance[area_8] = (min_y - y)[area_8]\n",
    "\n",
    "    # --Compute distances for points inside the square\n",
    "    min_edge_distance[area_5] = -torch.min(torch.stack([y - min_y, max_y - y, x - min_x, max_x - x]), dim=0)[0][area_5]\n",
    "    \n",
    "    return min_edge_distance\n",
    "\n",
    "\n",
    "def get_render_log_prob(min_edge_distance, blur=1e-4):\n",
    "    \"\"\"\n",
    "    Returns the (log) probability map used for soft rasterization as specified by\n",
    "    equation (1) of\n",
    "    https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Soft_Rasterizer_A_Differentiable_Renderer_for_Image-Based_3D_Reasoning_ICCV_2019_paper.pdf\n",
    "    \n",
    "    Also visualized here https://www.desmos.com/calculator/5z95dy2mny\n",
    "    \n",
    "    Args\n",
    "        min_edge_distance [*shape]\n",
    "        blur [] (default 1e-4): this is the σ in equation (1)\n",
    "    \n",
    "    Returns [*shape]\n",
    "    \"\"\"\n",
    "    return F.logsigmoid(-torch.sign(min_edge_distance) * min_edge_distance**2 / blur)\n",
    "\n",
    "\n",
    "def soft_render_square(square, location, background, background_depth=1e-4, color_sharpness=1e-4, blur=1e-4):\n",
    "    \"\"\"Draws a square on a canvas whose xy limits are [-1, 1].\n",
    "    \n",
    "    Follows equations (2) and (3) in\n",
    "    https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Soft_Rasterizer_A_Differentiable_Renderer_for_Image-Based_3D_Reasoning_ICCV_2019_paper.pdf\n",
    "\n",
    "    Args\n",
    "        square\n",
    "        location [2]\n",
    "        background [num_channels, num_rows, num_cols] -- this is the background color C_b in equation (2)\n",
    "        background_weight [] (default 1.): ϵ in equation (3)\n",
    "        color_sharpness [] (default 1e-4): γ in equation (3)\n",
    "        blur [] (default 1e-4): this is the σ in equation (1)\n",
    "\n",
    "    Returns\n",
    "        new_canvas [num_channels, num_rows, num_cols]\n",
    "    \"\"\"\n",
    "    # Canvas xy\n",
    "    # [num_rows, num_cols]\n",
    "    canvas_x, canvas_y = get_canvas_xy(num_rows, num_cols, device)\n",
    "    canvas_xy = torch.stack([canvas_x, canvas_y], dim=-1)\n",
    "\n",
    "    # Get render log prob\n",
    "    # --Foreground object (treat depth z = -1) [num_rows, num_cols]\n",
    "    depth = 0\n",
    "    square_render_log_prob = (\n",
    "        get_render_log_prob(get_min_edge_distance(square, location, canvas_xy), blur=blur) +\n",
    "        depth / color_sharpness\n",
    "    )\n",
    "    # --Background [num_rows, num_cols]\n",
    "    background_render_log_prob = torch.ones_like(square_render_log_prob) * background_depth / color_sharpness\n",
    "\n",
    "    # Compute color weight (equation (3))\n",
    "    # [num_rows, num_cols]\n",
    "    square_weight, background_weight = F.softmax(\n",
    "        torch.stack([square_render_log_prob, background_render_log_prob]), dim=0\n",
    "    )\n",
    "\n",
    "    return square_weight[None] * square.color[:, None, None] + background_weight[None] * background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7f6049cd50>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = soft_render_square(true_square, true_location, init_canvas(device),\n",
    "                         background_depth=1e-4, color_sharpness=1e-4, blur=1e-5)\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize learnable square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(location, learnable_square, background_depth, color_sharpness, blur, true_img):\n",
    "    num_channels, num_rows, num_cols = img.shape\n",
    "    loc = soft_render_square(learnable_square, location, init_canvas(device),\n",
    "                             background_depth=background_depth,\n",
    "                             color_sharpness=color_sharpness,\n",
    "                             blur=blur)\n",
    "    return -torch.distributions.Independent(\n",
    "        torch.distributions.Normal(loc, 1.), reinterpreted_batch_ndims=3\n",
    "    ).log_prob(true_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_square = Square(\"A\", torch.tensor([0.9, 0.2, 0.3], device=device), torch.tensor(0.3, device=device))\n",
    "true_location = torch.tensor([0.5, 0.5], device=device)\n",
    "true_img = render_square(true_square, true_location, init_canvas(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optim_step(optimizer, location, learnable_square, background_depth, color_sharpness, blur, true_img):\n",
    "    optimizer.zero_grad()\n",
    "    loss = get_loss(location, learnable_square, background_depth, color_sharpness, blur, true_img)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iter(img, img_hard_render, true_img, losses, img_path):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(4 * 4, 1 * 4))\n",
    "    axs[0].imshow(img.cpu().permute(1, 2, 0).detach().numpy())\n",
    "    axs[0].set_title(\"Soft render\")\n",
    "    axs[1].imshow(img_hard_render.cpu().permute(1, 2, 0).detach().numpy())\n",
    "    axs[1].set_title(\"Hard render\")\n",
    "    axs[2].imshow(true_img.cpu().permute(1, 2, 0).detach().numpy())\n",
    "    axs[2].set_title(\"Target\")\n",
    "    for ax in axs[:-1]:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    axs[3].plot(losses)\n",
    "    axs[3].set_title(\"Loss\")\n",
    "    axs[3].set_xlabel(\"Iteration\")\n",
    "    util.save_fig(fig, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:59:37 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 990/20000 [00:08<02:38, 120.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:59:46 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/1000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1994/20000 [00:17<02:26, 123.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:59:55 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/2000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 2996/20000 [00:26<02:17, 123.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:04 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/3000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 3995/20000 [00:34<02:17, 116.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:12 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/4000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5000/20000 [00:43<02:06, 118.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:21 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/5000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 5992/20000 [00:52<01:56, 120.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:30 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/6000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 6993/20000 [01:01<01:49, 119.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:39 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/7000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 7993/20000 [01:10<01:42, 117.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:48 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/8000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 8992/20000 [01:19<01:35, 115.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00:57 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/9000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 9999/20000 [01:28<01:28, 113.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:06 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/10000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 10991/20000 [01:36<01:15, 118.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:14 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/11000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 11997/20000 [01:45<01:06, 120.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:23 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/12000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13000/20000 [01:54<00:59, 116.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:32 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/13000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 13989/20000 [02:03<00:48, 123.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:40 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/14000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15000/20000 [02:11<00:43, 114.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:49 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/15000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 15997/20000 [02:20<00:34, 114.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:01:58 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/16000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 16989/20000 [02:29<00:26, 115.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:02:07 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/17000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 17995/20000 [02:38<00:17, 115.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:02:16 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/18000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 18991/20000 [02:47<00:08, 120.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:02:25 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:19 | INFO: Saved to tmp/19000.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [02:55<00:00, 113.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "learnable_square = LearnableSquare(\"A\").to(device)\n",
    "background_depth = nn.Parameter(torch.tensor(1e-4, device=device))\n",
    "color_sharpness = nn.Parameter(torch.tensor(1e-4, device=device))\n",
    "raw_blur = nn.Parameter(torch.randn((), device=device))\n",
    "raw_location = nn.Parameter(torch.randn((2,), device=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(\n",
    "    learnable_square.parameters(),\n",
    "    [raw_blur, raw_location]\n",
    "))\n",
    "\n",
    "# Optim\n",
    "num_iterations = 20000\n",
    "losses = []\n",
    "img_paths = []\n",
    "for iteration in tqdm(range(num_iterations)):\n",
    "    location = raw_location.sigmoid() * 2 - 1\n",
    "    blur = raw_blur.exp()\n",
    "    losses.append(\n",
    "        optim_step(optimizer, location, learnable_square, background_depth, color_sharpness, blur, true_img)\n",
    "    )\n",
    "    if iteration % 1000 == 0:\n",
    "        img = soft_render_square(learnable_square, location, init_canvas(device),\n",
    "                                 background_depth=background_depth,\n",
    "                                 color_sharpness=color_sharpness,\n",
    "                                 blur=blur)\n",
    "        img_hard_render = render_square(learnable_square, location, init_canvas(device))\n",
    "        \n",
    "        # Plot\n",
    "        img_paths.append(f\"tmp/{iteration}.png\")\n",
    "        plot_iter(img, img_hard_render, true_img, losses, img_paths[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:02:35 | /rdma/vast-rdma/vast/tenenbaum/tuananh/git/continuous_mws/stacking/util.py:28 | INFO: Saved to training.gif\n"
     ]
    }
   ],
   "source": [
    "util.make_gif(img_paths, \"training.gif\", fps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
